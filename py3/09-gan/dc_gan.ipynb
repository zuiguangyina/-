{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import logging\n",
    "from tensorflow import gfile\n",
    "import pprint\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from PIL import Image\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot = True)\n",
    "\n",
    "output_dir = './local_run'\n",
    "if not gfile.Exists(output_dir):\n",
    "    gfile.MakeDirs(output_dir)\n",
    "\n",
    "def get_default_params():\n",
    "    return tf.contrib.training.HParams(\n",
    "        z_dim = 100,\n",
    "        init_conv_size = 4,\n",
    "        g_channels = [128, 64, 32, 1],\n",
    "        d_channels = [32, 64, 128, 256],\n",
    "        batch_size = 128,\n",
    "        learning_rate = 0.002,\n",
    "        beta1 = 0.5,\n",
    "        img_size = 32,\n",
    "    )\n",
    "\n",
    "hps = get_default_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistData(object):\n",
    "    def __init__(self, mnist_train, z_dim, img_size):\n",
    "        self._data = mnist_train\n",
    "        self._example_num = len(self._data)\n",
    "        self._z_data = np.random.standard_normal((self._example_num, z_dim))\n",
    "        self._indicator = 0\n",
    "        self._resize_mnist_img(img_size)\n",
    "        self._random_shuffle()\n",
    "    \n",
    "    def _random_shuffle(self):\n",
    "        p = np.random.permutation(self._example_num)\n",
    "        self._z_data = self._z_data[p]\n",
    "        self._data = self._data[p]\n",
    "    \n",
    "    def _resize_mnist_img(self, img_size):\n",
    "        data = np.asarray(self._data * 255, np.uint8)\n",
    "        data = data.reshape((self._example_num, 1, 28, 28))\n",
    "        data = data.transpose((0, 2, 3, 1))\n",
    "        new_data = []\n",
    "        for i in range(self._example_num):\n",
    "            img = data[i].reshape((28, 28))\n",
    "            img = Image.fromarray(img)\n",
    "            img = img.resize((img_size, img_size))\n",
    "            img = np.asarray(img)\n",
    "            img = img.reshape((img_size, img_size, 1))\n",
    "            new_data.append(img)\n",
    "        new_data = np.asarray(new_data, dtype=np.float32)\n",
    "        new_data = new_data / 127.5 - 1\n",
    "        self._data = new_data\n",
    "        \n",
    "    def next_batch(self, batch_size):\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self._example_num:\n",
    "            self._random_shuffle()\n",
    "            self._indicator = 0\n",
    "            end_indicator = self._indicator + batch_size\n",
    "        assert end_indicator < self._example_num\n",
    "        \n",
    "        batch_data = self._data[self._indicator: end_indicator]\n",
    "        batch_z = self._z_data[self._indicator: end_indicator]\n",
    "        self._indicator = end_indicator\n",
    "        return batch_data, batch_z\n",
    "\n",
    "mnist_data = MnistData(mnist.train.images, hps.z_dim, hps.img_size)\n",
    "batch_data, batch_z = mnist_data.next_batch(5)\n",
    "print(batch_data.shape)\n",
    "print(batch_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_transpose(inputs, out_channel, name, training, with_bn_relu=True):\n",
    "    with tf.variable_scope(name):\n",
    "        conv2d_trans = tf.layers.conv2d_transpose(inputs, \n",
    "                                                  out_channel,\n",
    "                                                  [5, 5],\n",
    "                                                  strides=(2,2),\n",
    "                                                  padding='SAME')\n",
    "        if with_bn_relu:\n",
    "            bn = tf.layers.batch_normalization(conv2d_trans, training=training)\n",
    "            relu = tf.nn.relu(bn)\n",
    "            return relu\n",
    "        else:\n",
    "            return conv2d_trans\n",
    "\n",
    "def conv2d(inputs, out_channel, name, training):\n",
    "    def leaky_relu(x, leak = 0.2, name = ''):\n",
    "        return tf.maximum(x, x * leak, name = name)\n",
    "    with tf.variable_scope(name):\n",
    "        conv2d_output = tf.layers.conv2d(inputs,\n",
    "                                         out_channel,\n",
    "                                         [5, 5],\n",
    "                                         strides = (2, 2),\n",
    "                                         padding = 'SAME')\n",
    "        bn = tf.layers.batch_normalization(conv2d_output,\n",
    "                                           training = training)\n",
    "        return leaky_relu(bn, name = 'outputs')\n",
    "\n",
    "\n",
    "class Generator(object):\n",
    "    def __init__(self, channels, init_conv_size):\n",
    "        assert len(channels) > 1\n",
    "        self._channels = channels\n",
    "        self._init_conv_size = init_conv_size\n",
    "        self._reuse = False\n",
    "    \n",
    "    def __call__(self, inputs, training):\n",
    "        inputs = tf.convert_to_tensor(inputs)\n",
    "        with tf.variable_scope('generator', reuse=self._reuse):\n",
    "            with tf.variable_scope('inputs'):\n",
    "                fc = tf.layers.dense(\n",
    "                    inputs, \n",
    "                    self._channels[0] * self._init_conv_size * self._init_conv_size)\n",
    "                conv0 = tf.reshape(fc, [-1, self._init_conv_size, self._init_conv_size, self._channels[0]])\n",
    "                bn0 = tf.layers.batch_normalization(conv0, training=training)\n",
    "                relu0 = tf.nn.relu(bn0)\n",
    "            \n",
    "            deconv_inputs = relu0\n",
    "            # deconvolutions * 4\n",
    "            for i in range(1, len(self._channels)):\n",
    "                with_bn_relu = (i != len(self._channels) - 1)\n",
    "                deconv_inputs = conv2d_transpose(deconv_inputs,\n",
    "                                                 self._channels[i],\n",
    "                                                 'deconv-%d' % i,\n",
    "                                                 training,\n",
    "                                                 with_bn_relu)\n",
    "            img_inputs = deconv_inputs\n",
    "            with tf.variable_scope('generate_imgs'):\n",
    "                # imgs value scope: [-1, 1]\n",
    "                imgs = tf.tanh(img_inputs, name='imgaes')\n",
    "        self._reuse=True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator')\n",
    "        return imgs\n",
    "    \n",
    "        \n",
    "class Discriminator(object):\n",
    "    def __init__(self, channels):\n",
    "        self._channels = channels\n",
    "        self._reuse = False\n",
    "    \n",
    "    def __call__(self, inputs, training):\n",
    "        inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "        \n",
    "        conv_inputs = inputs\n",
    "        with tf.variable_scope('discriminator', reuse = self._reuse):\n",
    "            for i in range(len(self._channels)):\n",
    "                conv_inputs = conv2d(conv_inputs,\n",
    "                                     self._channels[i],\n",
    "                                     'deconv-%d' % i,\n",
    "                                     training)\n",
    "            fc_inputs = conv_inputs\n",
    "            with tf.variable_scope('fc'):\n",
    "                flatten = tf.layers.flatten(fc_inputs)\n",
    "                logits = tf.layers.dense(flatten, 2, name=\"logits\")\n",
    "        self._reuse = True\n",
    "        self.variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='discriminator')\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DCGAN(object):\n",
    "    def __init__(self, hps):\n",
    "        g_channels = hps.g_channels\n",
    "        d_channels = hps.d_channels\n",
    "        self._batch_size = hps.batch_size\n",
    "        self._init_conv_size = hps.init_conv_size\n",
    "        self._batch_size = hps.batch_size\n",
    "        self._z_dim = hps.z_dim\n",
    "        self._img_size = hps.img_size\n",
    "        \n",
    "        self._generator = Generator(g_channels, self._init_conv_size)\n",
    "        self._discriminator = Discriminator(d_channels)\n",
    "    \n",
    "    def build(self):\n",
    "        self._z_placholder = tf.placeholder(tf.float32, (self._batch_size, self._z_dim))\n",
    "        self._img_placeholder = tf.placeholder(tf.float32, \n",
    "                                               (self._batch_size, self._img_size, self._img_size, 1))\n",
    "        \n",
    "        generated_imgs = self._generator(self._z_placholder, training = True)\n",
    "        fake_img_logits = self._discriminator(generated_imgs, training = True)\n",
    "        real_img_logits = self._discriminator(self._img_placeholder, training = True)\n",
    "        \n",
    "        loss_on_fake_to_real = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels = tf.ones([self._batch_size], dtype = tf.int64),\n",
    "                logits = fake_img_logits))\n",
    "        loss_on_fake_to_fake = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels = tf.zeros([self._batch_size], dtype = tf.int64),\n",
    "                logits = fake_img_logits))\n",
    "        loss_on_real_to_real = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                labels = tf.ones([self._batch_size], dtype = tf.int64),\n",
    "                logits = real_img_logits))\n",
    "        \n",
    "        tf.add_to_collection('g_losses', loss_on_fake_to_real)\n",
    "        tf.add_to_collection('d_losses', loss_on_fake_to_fake)\n",
    "        tf.add_to_collection('d_losses', loss_on_real_to_real)\n",
    "        \n",
    "        \n",
    "        loss = {\n",
    "            'g': tf.add_n(tf.get_collection('g_losses'), name = 'total_g_loss'),\n",
    "            'd': tf.add_n(tf.get_collection('d_losses'), name = 'total_d_loss')\n",
    "        }\n",
    "        \n",
    "        return (self._z_placholder, self._img_placeholder, generated_imgs, loss)\n",
    "    \n",
    "    def build_train(self, losses, learning_rate, beta1):\n",
    "        g_opt = tf.train.AdamOptimizer(learning_rate = learning_rate, beta1 = beta1)\n",
    "        d_opt = tf.train.AdamOptimizer(learning_rate = learning_rate, beta1 = beta1)\n",
    "        g_opt_op = g_opt.minimize(losses['g'], var_list = self._generator.variables)\n",
    "        d_opt_op = d_opt.minimize(losses['d'], var_list = self._discriminator.variables)\n",
    "        with tf.control_dependencies([g_opt_op, d_opt_op]):\n",
    "            return tf.no_op(name = 'train')\n",
    "\n",
    "\n",
    "dcgan = DCGAN(hps)\n",
    "z_placeholder, img_placeholder, generated_imgs, losses = dcgan.build()\n",
    "train_op = dcgan.build_train(losses, hps.learning_rate, hps.beta1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_and_show_imgs(batch_imgs, img_size, rows=8, cols=16):\n",
    "    # batch_imgs: [batch_size, img_size, img_size, 1]\n",
    "    result_big_img = []\n",
    "    for i in range(rows):\n",
    "        row_imgs = []\n",
    "        for j in range(cols):\n",
    "            img = batch_imgs[cols * i + j]\n",
    "            img = img.reshape((img_size, img_size))\n",
    "            img = (img + 1) * 127.5\n",
    "            row_imgs.append(img)\n",
    "        row_imgs = np.hstack(row_imgs)\n",
    "        result_big_img.append(row_imgs)\n",
    "    result_big_img = np.vstack(result_big_img)\n",
    "    result_big_img = np.asarray(result_big_img, np.uint8)\n",
    "    result_big_img = Image.fromarray(result_big_img)\n",
    "    return result_big_img\n",
    "\n",
    "    \n",
    "    \n",
    "init_op = tf.global_variables_initializer()\n",
    "train_steps = 10000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    for step in range(train_steps):\n",
    "        batch_img, batch_z = mnist_data.next_batch(hps.batch_size)\n",
    "        \n",
    "        fetches = [train_op, losses['g'], losses['d']]\n",
    "        should_sample = (step + 1) % 50 == 0\n",
    "        if should_sample:\n",
    "            fetches += [generated_imgs]\n",
    "        out_values = sess.run(fetches,\n",
    "                              feed_dict = {\n",
    "                                  z_placeholder: batch_z,\n",
    "                                  img_placeholder: batch_img\n",
    "                              })\n",
    "        _, g_loss_val, d_loss_val = out_values[0:3]\n",
    "        logging.info('step: %d, g_loss: %4.3f, d_loss: %4.3f' % (step, g_loss_val, d_loss_val))\n",
    "        if should_sample:\n",
    "            gen_imgs_val = out_values[3]\n",
    "            \n",
    "            gen_img_path = os.path.join(output_dir, '%05d-gen.jpg' % (step + 1))\n",
    "            gt_img_path = os.path.join(output_dir, '%05d-gt.jpg' % (step + 1))\n",
    "            \n",
    "            gen_img = combine_and_show_imgs(gen_imgs_val, hps.img_size)\n",
    "            gt_img = combine_and_show_imgs(batch_img, hps.img_size)\n",
    "            \n",
    "            gen_img.save(gen_img_path)\n",
    "            gt_img.save(gt_img_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
